{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_temperatures = pd.read_json('input_data/temperature_modis.json')\n",
    "base_temperatures.sort_index(inplace=True)\n",
    "temperatures = base_temperatures.copy()\n",
    "base_temperatures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series modeling with ARIMA and SARIMAX in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "ax_lineplot = sns.lineplot(data = base_temperatures['lst_day'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(211)\n",
    "base_temperatures['lst_day'].hist()\n",
    "plt.subplot(212)\n",
    "base_temperatures['lst_day'].plot(kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and test sets division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_arima(dataset, training_size=0.8):\n",
    "    \"\"\"Function perform division of the dataset into training and test sets. It takes first XX% of records\n",
    "    as a training set and XX is a training size, where XX is a real value between 0 and 1 provided as a \n",
    "    training_size argument.\"\"\"\n",
    "    \n",
    "    dataset_len = len(dataset)\n",
    "    print('Dataset has: {} records'.format(\n",
    "    dataset_len))\n",
    "    limit = int(training_size * len(dataset))\n",
    "    training = dataset[:limit]\n",
    "    validation = dataset[limit:]\n",
    "    print('Training set has: {} records. Validation set has {} records.'.format(\n",
    "    len(training), len(validation)))\n",
    "    return training, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_day_train, lst_day_validation = prepare_data_for_arima(base_temperatures['lst_day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test - validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_abs_perc_error(predictions, validation_data):\n",
    "    mape = np.mean(np.abs(predictions - validation_data)/np.abs(validation_data))\n",
    "    return mape\n",
    "\n",
    "def test_walk_forward(train_set, validation_set):\n",
    "    observation = [train_set[-1]]  # The first predicted value\n",
    "    predictions = []\n",
    "    for i in range(len(validation_set)):\n",
    "        # Prediction\n",
    "        predictions.append(observation[-1])\n",
    "        # Observation\n",
    "        obs = validation_set[i]\n",
    "        observation.append(obs)\n",
    "    error_percent = mean_abs_perc_error(predictions, validation_set)\n",
    "    print(error_percent)\n",
    "    return error_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_error = test_walk_forward(lst_day_train, lst_day_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from scipy.stats import boxcox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is time series stationary? (no)\n",
    "\n",
    "fuller_test = adfuller(lst_day_train)\n",
    "print('ADF:', fuller_test[0])\n",
    "print('p-value:', fuller_test[1])\n",
    "print('critical values:', fuller_test[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line, ACF, PACF plots of an unchanged signal\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, sharex=False, figsize=(15, 7))\n",
    "axes[0].plot(lst_day_train.values)\n",
    "axes[0].set_title('Base signal')\n",
    "plot_acf(lst_day_train.values, ax=axes[1])\n",
    "plot_pacf(lst_day_train.values, ax=axes[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st order differentiation\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, sharex=False, figsize=(15, 7))\n",
    "axes[0].plot(lst_day_train.diff().values)\n",
    "axes[0].set_title('Signal differentiated one time')\n",
    "plot_acf(lst_day_train.diff().dropna().values, ax=axes[1])\n",
    "plot_pacf(lst_day_train.diff().dropna().values, ax=axes[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd order differentiation\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, sharex=False, figsize=(15, 7))\n",
    "axes[0].plot(lst_day_train.diff().diff().values)\n",
    "axes[0].set_title('Signal differentiated two times')\n",
    "plot_acf(lst_day_train.diff().diff().dropna().values, ax=axes[1])\n",
    "plot_pacf(lst_day_train.diff().diff().dropna().values, ax=axes[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is time series stationary after differentiation? (yes)\n",
    "\n",
    "fuller_test = adfuller(lst_day_train.diff().dropna().values)\n",
    "print('ADF:', fuller_test[0])\n",
    "print('p-value:', fuller_test[1])\n",
    "print('critical values:', fuller_test[4])\n",
    "print('')\n",
    "\n",
    "# Prediction for the model: AR = 1, I = 1, MA = 0 (p,d,q)\n",
    "\n",
    "model = ARIMA(lst_day_train.values, order=(1, 1, 0))\n",
    "model_fit = model.fit(trend='nc', disp=0)\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals\n",
    "\n",
    "residuals = pd.DataFrame(model_fit.resid)\n",
    "fig, ax = plt.subplots(1, 2, sharex=False, figsize=(15, 7))\n",
    "residuals.plot(title=\"Residuals\", ax=ax[0])\n",
    "residuals.plot(kind='kde', title='Density', ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 7))\n",
    "model_fit.plot_predict(dynamic=False, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model validation\n",
    "\n",
    "def arima_validation(training_set, validation_set, arima_model, model_order):\n",
    "    \n",
    "    history = list(training_set)\n",
    "    \n",
    "    # first prediction\n",
    "    predictions = []\n",
    "    predicted = float(arima_model.forecast()[0])\n",
    "    predictions.append(predicted)\n",
    "    history.append(validation_set[0])\n",
    "    \n",
    "    # rolling forecasts\n",
    "    for i in range(1, len(validation_set)):\n",
    "        model = ARIMA(history, model_order)\n",
    "        model_fit = model.fit(trend='nc', disp=0)\n",
    "        predicted = model_fit.forecast()[0]\n",
    "        predictions.append(predicted[0])\n",
    "        \n",
    "        # observation\n",
    "        obs = validation_set[i]\n",
    "        history.append(obs)\n",
    "        print('>> Predicted = {:.1f}, Expected = {:.1f}'.format(predicted[0], obs))\n",
    "    return predictions\n",
    "\n",
    "forecasts = arima_validation(lst_day_train.values, lst_day_validation.values, model_fit, (1, 1, 0))\n",
    "error_value = mean_abs_perc_error(forecasts, lst_day_validation.values)\n",
    "\n",
    "print('Error value is:', error_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 7))\n",
    "plt.plot(lst_day_validation.index, lst_day_validation.values)\n",
    "plt.plot(lst_day_validation.index, forecasts)\n",
    "plt.legend(['True value', 'Predictions'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARIMAX model\n",
    "\n",
    "model = SARIMAX(lst_day_train.values, order=(1, 1, 0), seasonal_order=(1, 1, 1, 12))\n",
    "model_fit = model.fit(trend='nc', disp=0)\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals\n",
    "\n",
    "residuals = pd.DataFrame(model_fit.resid)\n",
    "fig, ax = plt.subplots(1, 2, sharex=False, figsize=(15, 7))\n",
    "residuals.plot(title=\"Residuals\", ax=ax[0])\n",
    "residuals.plot(kind='kde', title='Density', ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARIMAX validation\n",
    "\n",
    "def sarima_validation(training_set, validation_set, sarima_model, model_order, seasonal_order):\n",
    "    \n",
    "    history = list(training_set)\n",
    "    \n",
    "    # first prediction\n",
    "    predictions = []\n",
    "    predicted = float(sarima_model.forecast()[0])\n",
    "    predictions.append(predicted)\n",
    "    history.append(validation_set[0])\n",
    "    \n",
    "    # rolling forecasts\n",
    "    for i in range(1, len(validation_set)):\n",
    "        model = SARIMAX(history, order=model_order, seasonal_order=seasonal_order)\n",
    "        model_fit = model.fit(trend='nc', disp=0)\n",
    "        predicted = model_fit.forecast()[0]\n",
    "        predictions.append(predicted)\n",
    "        \n",
    "        # observation\n",
    "        obs = validation_set[i]\n",
    "        history.append(obs)\n",
    "        print('>> Predicted = {:.1f}, Expected = {:.1f}'.format(predicted, obs))\n",
    "    return predictions\n",
    "\n",
    "forecasts = sarima_validation(lst_day_train.values, lst_day_validation.values, model_fit,\n",
    "                              (1, 1, 0), (1, 1, 1, 12))\n",
    "error_value = mean_abs_perc_error(forecasts, lst_day_validation.values)\n",
    "\n",
    "print('Error value is:', error_value)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 7))\n",
    "plt.plot(lst_day_validation.index, lst_day_validation.values)\n",
    "plt.plot(lst_day_validation.index, forecasts)\n",
    "plt.legend(['True value', 'Predictions'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_walk_forward_by_period(train_set, validation_set, period=12):\n",
    "    j = -period\n",
    "    observation = [train_set[j]]  # The first predicted value\n",
    "    predictions = []\n",
    "    for i in range(len(validation_set)):\n",
    "        # Prediction\n",
    "        predictions.append(observation[-1])\n",
    "        # Observation\n",
    "        j = j + 1\n",
    "        if j < 0:\n",
    "            obs = train_set[j]\n",
    "        else:\n",
    "            obs = validation_set[i-(period-1)]\n",
    "        observation.append(obs)\n",
    "    error_percent = mean_abs_perc_error(predictions, validation_set)\n",
    "    return error_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('>> Seasonal base error is:', test_walk_forward_by_period(lst_day_train, lst_day_validation), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
